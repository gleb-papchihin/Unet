{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqG5YsOrxKFH"
      },
      "source": [
        "import torch.utils.model_zoo as modelzoo\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "from torchvision import models\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "\n",
        "import typing as tp\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV48rGOxxwDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb91b113-5b32-43ab-a57d-dce57d447841"
      },
      "source": [
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bh2796_y6zA",
        "cellView": "form"
      },
      "source": [
        "# @title <h5>Pathfinder</h5>\n",
        "\n",
        "class GTEAPaths:\n",
        "    def __init__(self, path_to_folder: str, shuffle: bool=True,\n",
        "        seed: tp.Optional[int]=None):\n",
        "        \n",
        "        self.path_to_image = \"/\".join([path_to_folder, \"image\"])\n",
        "        self.path_to_mask = \"/\".join([path_to_folder, \"mask\"])\n",
        "        self.folder = Path(self.path_to_image)\n",
        "        self.paths = self._load_paths()\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        if shuffle is True:\n",
        "            random.shuffle(self.paths)\n",
        "\n",
        "    def _load_paths(self) -> tp.List[tp.Tuple[str, str]]:\n",
        "        paths = []\n",
        "        for file in self.folder.glob(\"*\"):\n",
        "            filename = file.name\n",
        "            if \".mat\" in filename:\n",
        "                continue\n",
        "            image_path = str(file)\n",
        "            mask_name = filename[:filename.find(\".\")] + \".png\"\n",
        "            mask_path = \"/\".join([self.path_to_mask, mask_name])\n",
        "            paths.append((image_path, mask_path))\n",
        "        return paths\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return self.paths[index]\n",
        "\n",
        "class EgoHandPaths:\n",
        "    def __init__(self, path_to_folder: str, shuffle: bool=True,\n",
        "        seed: tp.Optional[int]=None):\n",
        "        \n",
        "        self.path_to_image = \"/\".join([path_to_folder, \"image\"])\n",
        "        self.path_to_mask = \"/\".join([path_to_folder, \"mask\"])\n",
        "        self.folder = Path(self.path_to_image)\n",
        "        self.paths = self._load_paths()\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        if shuffle is True:\n",
        "            random.shuffle(self.paths)\n",
        "\n",
        "    def _load_paths(self) -> tp.List[tp.Tuple[str, str]]:\n",
        "        paths = []\n",
        "        for subfolder in self.folder.glob(\"*\"):\n",
        "            subname = subfolder.name\n",
        "            for file in subfolder.glob(\"*\"):\n",
        "                filename = file.name\n",
        "                if \".mat\" in filename:\n",
        "                    continue\n",
        "                image_path = str(file)\n",
        "                mask_name = filename[6:]\n",
        "                mask_path = \"/\".join([self.path_to_mask, subname, mask_name])\n",
        "                paths.append((image_path, mask_path))\n",
        "        return paths\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return self.paths[index]\n",
        "\n",
        "class Ego2HandPaths:\n",
        "    def __init__(self, path_to_folder: str, path_to_background: str, \n",
        "        shuffle: bool=True, seed: tp.Optional[int]=None):\n",
        "        self.bg_folder = Path(path_to_background)\n",
        "        self.bg_paths = self._load_bg_paths()\n",
        "        self.folder = Path(path_to_folder)\n",
        "        self.paths = self._load_paths()\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        if shuffle is True:\n",
        "            random.shuffle(self.paths)\n",
        "\n",
        "    def _load_bg_paths(self) -> tp.List[str]:\n",
        "        files = self.bg_folder.glob('*')\n",
        "        bg_paths = []\n",
        "        for file in files:\n",
        "            bg_paths.append(str(file))\n",
        "        return bg_paths\n",
        "\n",
        "    def _get_random_background(self):\n",
        "        return random.choice(self.bg_paths)\n",
        "\n",
        "    def _load_paths(self) -> tp.List[tp.Tuple[str, str]]:\n",
        "        paths = []\n",
        "        for action in self.folder.glob('*'):\n",
        "            for sequence in action.glob('*'):\n",
        "                for files in sequence.glob('*'):\n",
        "                    images = list(files.glob('*'))\n",
        "                    if len(images[0].name) == 9:\n",
        "                        image = str(images[0])\n",
        "                        mask = str(images[1])\n",
        "                    else:\n",
        "                        image = str(images[1])\n",
        "                        mask = str(images[0])\n",
        "                    paths.append((image, mask, self._get_random_background()))\n",
        "        return paths\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return self.paths[index]\n",
        "\n",
        "class UnionPaths:\n",
        "    def __init__(self, paths: tp.List[tp.Tuple], \n",
        "        shuffle: bool=True, seed: tp.Optional[int]=None):\n",
        "\n",
        "        self.paths = paths\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        if shuffle is True:\n",
        "            random.shuffle(self.paths)\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return self.paths[index]\n",
        "\n",
        "class AugmentationPaths:\n",
        "    def __init__(self, paths: tp.List[tp.Tuple], angles: tp.Tuple[int, int]=(-180, 180),\n",
        "        seed: tp.Optional[int]=None, shuffle: bool=True, augmentate: bool=True):\n",
        "        \n",
        "        # [color, rotation, hflip, vflip]\n",
        "        self.changes = []\n",
        "        self.paths = []\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "        for path in paths:\n",
        "            self.paths.append(path)\n",
        "            self.changes.append([0, 0, False, False])\n",
        "            \n",
        "            if augmentate is False:\n",
        "                continue\n",
        "                \n",
        "            angle = random.randint(angles[0], angles[1])\n",
        "            color = random.choice([1, 2])\n",
        "            hflip = random.choice([True, False])\n",
        "            vflip = random.choice([True, False])\n",
        "            self.paths.append(path)\n",
        "            self.changes.append([color, angle, hflip, vflip])\n",
        "\n",
        "        if shuffle is True:\n",
        "            random.shuffle(self.paths)\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return (self.paths[index], self.changes[index])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-YnSMJwLzPUK"
      },
      "source": [
        "# @title <h5>Loader</h5>\n",
        "\n",
        "class Loader:\n",
        "    def __init__(self, data: tp.List[ tp.Union[tp.Tuple[str, str, str], tp.Tuple[str, str]]]):\n",
        "\n",
        "        \"\"\"\n",
        "        Convert pathes to PIL Images\n",
        "        \"\"\"\n",
        "\n",
        "        self.aug_params = []\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "        for item in data:\n",
        "            collection = item[0]\n",
        "            if len(collection) == 2:\n",
        "                image = Image.open(collection[0])\n",
        "                mask = Image.open(collection[1])\n",
        "                self.images.append(image)\n",
        "                self.masks.append(mask)\n",
        "            elif len(collection) == 3:\n",
        "                image = Image.open(collection[0])\n",
        "                mask = Image.open(collection[1])\n",
        "                background = Image.open(collection[2])\n",
        "                image = self.paste(image, background)\n",
        "                self.images.append(image)\n",
        "                self.masks.append(mask)\n",
        "            self.aug_params.append(item[1])\n",
        "\n",
        "    def paste(self, image, background):\n",
        "        background = background.resize(image.size)        \n",
        "        background.paste(image, (0,0), image)\n",
        "        return background\n",
        "\n",
        "    def __getitem__(self, index: tp.Union[int, slice]):\n",
        "        items = []\n",
        "        if isinstance(index, slice):\n",
        "            start = 0 if index.start is None else index.start\n",
        "            stop = len(self) if index.stop is None else index.stop\n",
        "            step = 1 if index.step is None else index.step\n",
        "            for i in range(start, stop, step):\n",
        "                if i < len(self):\n",
        "                    items.append(self(i))\n",
        "        else:\n",
        "            items.append(self(index))\n",
        "        return items\n",
        "\n",
        "    def __call__(self, index: int):\n",
        "        return (self.aug_params[index], (self.images[index], self.masks[index]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOuj5HyYzV-_",
        "cellView": "form"
      },
      "source": [
        "# @title <h5>Preprocessor</h5>\n",
        "\n",
        "class AugPreprocessor:\n",
        "    def __init__(self, resize: tp.Tuple[int, int]):\n",
        "        self.resize = resize\n",
        "\n",
        "        self.to_gray = transforms.Grayscale(3)\n",
        "        self.jitter = transforms.ColorJitter(brightness=.5, hue=.3)\n",
        "        \n",
        "        self.x_preprocessor = transforms.Compose([\n",
        "            transforms.Resize(self.resize),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.y_preprocessor = transforms.Compose([\n",
        "            transforms.Resize(self.resize),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def preprocess(self, collection, aug_params, bitwise: bool=False):\n",
        "        \n",
        "        color = aug_params[0]\n",
        "        angle = aug_params[1]\n",
        "        hflip = aug_params[2]\n",
        "        vflip = aug_params[3]\n",
        "\n",
        "        image = self.x_preprocessor(collection[0])\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = self.y_preprocessor(collection[1])\n",
        "        mask = mask.unsqueeze(0).type(torch.BoolTensor)\n",
        "\n",
        "        if color==1:\n",
        "            image = self.to_gray(image)\n",
        "        elif color==2:\n",
        "            image = self.jitter(image)\n",
        "        if angle != 0:\n",
        "            image = transforms.functional.rotate(image, angle)\n",
        "            mask = transforms.functional.rotate(mask, angle)\n",
        "        if hflip:\n",
        "            image = transforms.functional.hflip(image)\n",
        "            mask = transforms.functional.hflip(mask)\n",
        "        if vflip:\n",
        "            image = transforms.functional.vflip(image)\n",
        "            mask = transforms.functional.vflip(mask)\n",
        "\n",
        "        if bitwise is True:\n",
        "            reverse_mask = torch.bitwise_not(mask)\n",
        "            mask = torch.cat([mask, reverse_mask], dim=1)\n",
        "        return image, mask\n",
        "\n",
        "    def __call__(self, data, bitwise: bool=False):\n",
        "        images = []\n",
        "        masks = []\n",
        "        for item in data:\n",
        "            aug_param, collection = item\n",
        "            image, mask = self.preprocess(collection, aug_param, bitwise)\n",
        "            images.append(image)\n",
        "            masks.append(mask)\n",
        "        x = torch.cat(images, dim=0)\n",
        "        y = torch.cat(masks, dim=0)\n",
        "        return x, y\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, resize: tp.Tuple[int, int]):\n",
        "        self.resize = resize\n",
        "        \n",
        "        self.x_preprocessor = transforms.Compose([\n",
        "            transforms.Resize(self.resize),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        self.y_preprocessor = transforms.Compose([\n",
        "            transforms.Resize(self.resize),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def preprocess(self, collection, bitwise: bool=False):\n",
        "        image = self.x_preprocessor(collection[0])\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = self.y_preprocessor(collection[1])\n",
        "        mask = mask.unsqueeze(0).type(torch.BoolTensor)\n",
        "        if bitwise is True:\n",
        "            reverse_mask = torch.bitwise_not(mask)\n",
        "            mask = torch.cat([mask, reverse_mask], dim=1)\n",
        "        return image, mask\n",
        "\n",
        "    def __call__(self, data, bitwise: bool=False):\n",
        "        images = []\n",
        "        masks = []\n",
        "        for collection in data:\n",
        "            image, mask = self.preprocess(collection, bitwise)\n",
        "            images.append(image)\n",
        "            masks.append(mask)\n",
        "        x = torch.cat(images, dim=0)\n",
        "        y = torch.cat(masks, dim=0)\n",
        "        return x, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CahsFN0tztWT",
        "cellView": "form"
      },
      "source": [
        "# @title <h5>Utils</h5>\n",
        "\n",
        "def create_history():\n",
        "    history = {\n",
        "        \"mIOU\": [],\n",
        "        \"Loss\": [],\n",
        "        \"PixelAccuracy\": []\n",
        "    }\n",
        "    return history\n",
        "\n",
        "def create_meta():\n",
        "    meta = {\n",
        "        \"zip_slice_index\": 0,\n",
        "        \"epoch\": 0,\n",
        "        \"batch\": 0\n",
        "    }\n",
        "    return meta\n",
        "\n",
        "def save_json(path, data):\n",
        "    with open(path, 'w') as file:\n",
        "        json.dump(data, file)\n",
        "\n",
        "def load_json(path):\n",
        "    with open(path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def is_loadable(path: tp.Optional[str]) -> bool:\n",
        "    if path is None:\n",
        "        return False\n",
        "    if Path(path).exists() is False:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def backgrounds_was_loaded(path: str):\n",
        "    folder = Path(path)\n",
        "    if not folder.exists():\n",
        "        return False\n",
        "    if len(list(folder.glob(\"*\"))) == 0:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def create_folder(path):\n",
        "    folder = Path(path)\n",
        "    folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def delete_folder(path_to_folder: str):\n",
        "    folder = Path(path_to_folder)\n",
        "    if folder.exists() is True:\n",
        "        shutil.rmtree(folder)\n",
        "\n",
        "def split_on_batches(paths, batch_size):\n",
        "    n_batches = len(paths) // batch_size\n",
        "    batches = []\n",
        "    for i in range(n_batches):\n",
        "        start = i * batch_size\n",
        "        stop = start + batch_size\n",
        "        batch = paths[start:stop]\n",
        "        batches.append(batch)\n",
        "    return batches\n",
        "\n",
        "def extract_zip(path_to_zip :str,\n",
        "    slice: tp.Optional[tp.Tuple[int, int]]=None) -> None:\n",
        "    with ZipFile(path_to_zip, 'r') as zip:\n",
        "        namelist = zip.namelist()\n",
        "        if slice is None:\n",
        "            start, stop = (0, len(namelist))\n",
        "        else:\n",
        "            start, stop = slice\n",
        "        zip.extractall(members=namelist[start: stop])\n",
        "\n",
        "def create_heatmap(image, mask, alpha: float=0.4):\n",
        "    convert_to_pil = transforms.ToPILImage()\n",
        "    image = convert_to_pil(image).convert(\"RGB\")\n",
        "    mask = convert_to_pil(mask).convert(\"RGB\")\n",
        "    heatmap = Image.blend(image, mask, alpha)\n",
        "    return heatmap\n",
        "\n",
        "def save_heatmap(path, heatmap):\n",
        "    heatmap.save(path)\n",
        "\n",
        "def create_heatmap_from_folder(path_to_input, path_to_output, \n",
        "    model, preprocessor, device, alpha: float=0.2):\n",
        "\n",
        "    folder = Path(path_to_input)\n",
        "\n",
        "    if not folder.exists():\n",
        "        raise Exception(\"Folder does not exists\")\n",
        "\n",
        "    for i, image_path in enumerate(folder.glob(\"*\")):\n",
        "        with torch.no_grad():\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            x = preprocessor.x_preprocessor(image)\n",
        "            x = x.unsqueeze(0)\n",
        "            x = x.to(device).float()\n",
        "            pred = model(x)\n",
        "            mask = convert_prediction_to_mask(pred[0]).float()\n",
        "            heatmap = create_heatmap(x[0], mask, alpha)\n",
        "            path = path_to_output + \"/\" + str(i) + \".jpg\"\n",
        "            save_heatmap(path, heatmap)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lUK28iTFz03Y"
      },
      "source": [
        "# @title <h5>Verbose</h5>\n",
        "\n",
        "def get_statistics(subset: tp.Tuple[float]) -> tp.Tuple[float, float, float]:\n",
        "    \n",
        "    \"\"\"\n",
        "    Return median, mean, std for a subset.\n",
        "    \"\"\"\n",
        "\n",
        "    median = torch.tensor(subset).median().item()\n",
        "    mean = torch.tensor(subset).mean().item()\n",
        "    std = torch.tensor(subset).std().item()\n",
        "    return median, mean, std\n",
        "\n",
        "def show_state(epoch_index: int, batch_index: int, \n",
        "    subset_loss: tp.List[float], subset_miou: tp.List[float], \n",
        "    subset_mpa: tp.List[float], delimiter: str=\"*\") -> None:\n",
        "    \n",
        "    \"\"\"\n",
        "    Show value of metrics while training.\n",
        "    MPA is Mean Pixel accuracy\n",
        "    MIou is Mean Intersection over union\n",
        "    \"\"\"\n",
        "\n",
        "    loss_median, loss_mean, loss_std = get_statistics(subset_loss)\n",
        "    miou_median, miou_mean, miou_std = get_statistics(subset_miou)\n",
        "    mpa_median, mpa_mean, mpa_std = get_statistics(subset_mpa)\n",
        "    \n",
        "    print(delimiter, delimiter, delimiter)\n",
        "    print()\n",
        "    print(f\"Epoch       : {epoch_index}\")\n",
        "    print(f\"Batch       : {batch_index}\")\n",
        "    print()\n",
        "    print(f\"LOSS Median : {loss_median}\")\n",
        "    print(f\"LOSS Mean   : {loss_mean}\")\n",
        "    print(f\"LOSS std    : {loss_std}\")\n",
        "    print()\n",
        "    print(f\"MIoU Median : {miou_median}\")\n",
        "    print(f\"MIoU Mean   : {miou_mean}\")\n",
        "    print(f\"MIoU Std    : {miou_std}\")\n",
        "    print()\n",
        "    print(f\"MPA Median : {mpa_median}\")\n",
        "    print(f\"MPA Mean   : {mpa_mean}\")\n",
        "    print(f\"MPA Std    : {mpa_std}\")\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5C6oOECJz7C8"
      },
      "source": [
        "# @title <h5>Metrics</h5>\n",
        "\n",
        "def convert_prediction_to_mask(prediction, thr: float=0):\n",
        "    mask = prediction > thr\n",
        "    return mask\n",
        "\n",
        "# INTERSECTION OVER UNION\n",
        "def get_iou(prediction, target):\n",
        "\n",
        "    if target.shape != prediction.shape:\n",
        "        raise Exception('A target shape doesn`t match with a prediction shape')\n",
        "\n",
        "    if target.dim() != 3:\n",
        "        raise Exception(f'A target dim is {target.dim()}. Must be 3.')\n",
        "\n",
        "    pred_copy = prediction.clone()\n",
        "    pred_copy = convert_prediction_to_mask(pred_copy)\n",
        "    \n",
        "    target_copy = target.clone()\n",
        "    target_copy = convert_prediction_to_mask(target_copy)\n",
        "\n",
        "    intersection = torch.bitwise_and(target_copy, pred_copy).sum().item()\n",
        "    union = torch.bitwise_or(target_copy, pred_copy).sum().item()\n",
        "    \n",
        "    if (target_copy.sum().item() == 0) and (pred_copy.sum().item() == 0):\n",
        "        return 1\n",
        "    elif union == 0:\n",
        "        return 0\n",
        "\n",
        "    return intersection / union\n",
        "\n",
        "def get_mean_iou(predictions, targets):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if targets.shape != predictions.shape:\n",
        "            raise Exception('A targets shape doesn`t match with a predictions shape')\n",
        "\n",
        "        if targets.dim() != 4:\n",
        "            raise Exception(f'A target dim is {targets.dim()}. Must be 4.')\n",
        "\n",
        "        iou_sum = 0\n",
        "        for i in range(targets.shape[0]):\n",
        "            iou = get_iou(targets[i], predictions[i])\n",
        "            iou_sum += iou\n",
        "        mean_iou = iou_sum / targets.shape[0]\n",
        "        return mean_iou\n",
        "\n",
        "# PIXEL ACCURACY\n",
        "def get_pixel_acc(prediction, target):\n",
        "\n",
        "    if target.shape != prediction.shape:\n",
        "        raise Exception('A target shape doesn`t match with a prediction shape')\n",
        "\n",
        "    if target.dim() != 3:\n",
        "        raise Exception(f'A target dim is {target.dim()}. Must be 3.')\n",
        "\n",
        "    pred_copy = prediction.clone()\n",
        "    pred_copy = convert_prediction_to_mask(pred_copy)\n",
        "\n",
        "    target_copy = target.clone()\n",
        "    target_copy = convert_prediction_to_mask(target_copy)\n",
        "\n",
        "    same = (target_copy == pred_copy).sum().item()\n",
        "    channels, height, width = target.shape\n",
        "    area = height * width * channels\n",
        "    acc = same / area\n",
        "    return acc\n",
        "\n",
        "def get_mean_pixel_acc(predictions, targets):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if targets.shape != predictions.shape:\n",
        "            raise Exception('A targets shape doesn`t match with a predictions shape')\n",
        "\n",
        "        if targets.dim() != 4:\n",
        "            raise Exception(f'A target dim is {targets.dim()}. Must be 4.')\n",
        "\n",
        "        acc_sum = 0\n",
        "        for i in range(targets.shape[0]):\n",
        "            acc = get_pixel_acc(targets[i], predictions[i])\n",
        "            acc_sum += acc\n",
        "        mean_acc = acc_sum / targets.shape[0]\n",
        "        return mean_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yU3Tap8Z0EBs"
      },
      "source": [
        "# @title <h5>Checkpoint</h5>\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"\n",
        "    Prefer to GPU\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def optimizer_to(optimizer, device):\n",
        "    for param in optimizer.state.values():\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)\n",
        "\n",
        "def create_checkpoint(path, model, optimizer, loss_fn):\n",
        "    to_save = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'loss_fn': loss_fn.state_dict(),\n",
        "    }\n",
        "    torch.save(to_save, path)\n",
        "\n",
        "def save_model(path, model):\n",
        "    to_save = {\n",
        "        'model': model.state_dict(),\n",
        "    }\n",
        "    torch.save(to_save, path)\n",
        "\n",
        "def load_checkpoint(path, device):\n",
        "    return torch.load(path, map_location=device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmIO6zBn0K7k",
        "cellView": "form"
      },
      "source": [
        "# @title <h5>Fit</h5>\n",
        "\n",
        "def fit(batches: tp.List[tp.List], loader, preprocessor, model, optimizer, loss_fn, \n",
        "    epochs: int, ckpt_path: tp.Optional[str]=None, ckpt_per_iter: tp.Optional[int]=None,\n",
        "    verbose_per_iter: tp.Optional[int]=None, history_path: tp.Optional[str]=None,\n",
        "    meta_path: tp.Optional[str]=None, heatmap_input: tp.Optional[str]=None,\n",
        "    heatmap_output: tp.Optional[str]=None, heatmap_per_iter: tp.Optional[int]=None):\n",
        "\n",
        "    n_batches = len(batches)\n",
        "\n",
        "    # GPU is preferred\n",
        "    device = get_device()\n",
        "\n",
        "    # Load model from checkpoint\n",
        "    if is_loadable(ckpt_path):\n",
        "        print(\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~\")\n",
        "        print(\"Checkpoint was found\")\n",
        "        print(\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~\")\n",
        "        print()\n",
        "        checkpoint = load_checkpoint(ckpt_path, device)\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        loss_fn.load_state_dict(checkpoint['loss_fn'])\n",
        "\n",
        "    # Load history\n",
        "    if is_loadable(history_path) and history_path is not None:\n",
        "        history = load_json(history_path)\n",
        "    elif not is_loadable(history_path) and history_path is not None:\n",
        "        history = create_history()\n",
        "\n",
        "    # Load meta\n",
        "    if is_loadable(meta_path) and meta_path is not None:\n",
        "        meta = load_json(meta_path)\n",
        "    elif not is_loadable(meta_path) and meta_path is not None:\n",
        "        meta = create_meta()\n",
        "\n",
        "    # Read parameters\n",
        "    start_epoch = meta[\"epoch\"]\n",
        "    start_batch = meta[\"batch\"]\n",
        "\n",
        "    # Switch to device\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer_to(optimizer, device)\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "\n",
        "        subset_loss = []\n",
        "        subset_miou = []\n",
        "        subset_mpa = []\n",
        "\n",
        "        for i in range(start_batch, len(batches)):\n",
        "\n",
        "            batch = batches[i]\n",
        "\n",
        "            # Data\n",
        "            torch.cuda.empty_cache()\n",
        "            loaded = loader(batch)\n",
        "            x, y = preprocessor(loaded[:])\n",
        "            x = x.to(device).float()\n",
        "            y = y.to(device).float()\n",
        "\n",
        "            # Step\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Metrics\n",
        "            miou = get_mean_iou(pred, y)\n",
        "            mpa = get_mean_pixel_acc(pred, y)\n",
        "\n",
        "            # Add to buffer\n",
        "            subset_loss.append(loss.item())\n",
        "            subset_miou.append(miou)\n",
        "            subset_mpa.append(mpa)\n",
        "\n",
        "            # Add to history\n",
        "            history['Loss'].append(loss.item())\n",
        "            history['PixelAccuracy'].append(mpa)\n",
        "            history['mIOU'].append(miou)\n",
        "\n",
        "            # change meta batch\n",
        "            meta[\"batch\"] += 1\n",
        "\n",
        "            # Verbose state of training\n",
        "            if verbose_per_iter is not None:\n",
        "                if (i+1) % verbose_per_iter == 0:\n",
        "                    show_state(epoch, i+1, subset_loss, subset_miou, subset_mpa)\n",
        "                    subset_loss = []\n",
        "                    subset_miou = []\n",
        "                    subset_mpa = []\n",
        "\n",
        "            # Create checkpoint\n",
        "            if (ckpt_path is not None) and (ckpt_per_iter is not None):\n",
        "                if (i+1) % ckpt_per_iter == 0:\n",
        "                    if meta_path is not None:\n",
        "                        save_json(meta_path, meta)\n",
        "                    if history_path is not None:\n",
        "                        save_json(history_path, history)\n",
        "                    create_checkpoint(ckpt_path, model, optimizer, loss_fn)\n",
        "            \n",
        "            if (heatmap_input is not None) and (heatmap_output is not None) and (heatmap_per_iter is not None):\n",
        "                if (i+1) % heatmap_per_iter == 0:\n",
        "                    if heatmap_output[-1] == \"/\":\n",
        "                        current_output = f\"{heatmap_output}{epoch}{i+1}\"\n",
        "                    else:\n",
        "                        current_output = f\"{heatmap_output}/{epoch}{i+1}\"\n",
        "                    create_folder(current_output)\n",
        "                    create_heatmap_from_folder(heatmap_input, current_output,\n",
        "                        model, preprocessor, device, alpha=0.4)\n",
        "            \n",
        "        # change meta epoch\n",
        "        meta[\"epoch\"] += 1\n",
        "        meta[\"batch\"] = 0\n",
        "        start_batch = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-VrFLVQ0YJy",
        "cellView": "form"
      },
      "source": [
        "# @title <h5>Unet</h5>\n",
        "\n",
        "class ConvReLUBN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "        padding=0, stride=1, dilation=1, bias=False, separable=False):\n",
        "        super(ConvReLUBN, self).__init__()\n",
        "\n",
        "        groups = in_channels if separable else 1\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
        "            padding=padding, stride=stride, dilation=dilation, bias=bias, groups=groups)\n",
        "        self.norm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "class Exploration(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Exploration, self).__init__()\n",
        "        self.sequence = nn.Sequential(\n",
        "            ConvReLUBN(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            ConvReLUBN(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sequence(x)\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features: tp.List[int]=[64, 128, 256, 512]):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "\n",
        "        for feature in features:\n",
        "            self.downs.append(Exploration(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(nn.Conv2d(feature*2, feature, kernel_size=1, bias=False))\n",
        "            self.ups.append(Exploration(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = Exploration(features[-1], features[-1]*2)\n",
        "        self.output = nn.Conv2d(features[0], out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for index in range(0, len(self.ups), 2):\n",
        "            skip_connection = skip_connections[index//2]\n",
        "            size = skip_connection.shape[2:]\n",
        "            x = self.ups[index](x)\n",
        "            x = F.interpolate(x, size=size, mode=\"bilinear\", align_corners=True)\n",
        "            concat = torch.cat([x, skip_connection], dim=1)\n",
        "            x = self.ups[index + 1](concat)\n",
        "\n",
        "        return self.output(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251LTM8Mx2Gq"
      },
      "source": [
        "subset_0_4 = \"/content/drive/MyDrive/Use_your_hands/Dataset/Ego2Hand_0_4.zip\"\n",
        "subset_5_10 = \"/content/drive/MyDrive/Use_your_hands/Dataset/Ego2Hand_5_10.zip\"\n",
        "subset_11_16 = \"/content/drive/MyDrive/Use_your_hands/Dataset/Ego2Hand_11_16.zip\"\n",
        "subset_17_21 = \"/content/drive/MyDrive/Use_your_hands/Dataset/Ego2Hand_17_21.zip\"\n",
        "backgrounds = \"/content/drive/MyDrive/Use_your_hands/Dataset/backgrounds.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28RuaXjGyDra"
      },
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/Unet/pretrained/UnetBilinear.pt\"\n",
        "meta_path = \"/content/drive/MyDrive/Unet/meta/UnetBilinear.json\"\n",
        "history_path = \"/content/drive/MyDrive/Unet/history/UnetBilinear.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpCvxM1YTCu0"
      },
      "source": [
        "heatmap_input = \"/content/drive/MyDrive/Unet/heatmap/input\"\n",
        "heatmap_output = \"/content/drive/MyDrive/Unet/heatmap/output/bilinear\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4RvOG0X0Uuk"
      },
      "source": [
        "extract_zip(backgrounds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yienB2_M01SG"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Dataset/HandOverFace.zip\n",
        "!unzip /content/drive/MyDrive/Dataset/EgoHand.zip\n",
        "!unzip /content/drive/MyDrive/Dataset/GTEA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DRx5CQx02tY"
      },
      "source": [
        "resize = (240, 320)\n",
        "model = Unet()\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "preprocessor = AugPreprocessor(resize)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5S8z19t1G5a"
      },
      "source": [
        "if is_loadable(meta_path):\n",
        "    meta = load_json(meta_path)\n",
        "    start_epoch = meta[\"epoch\"]\n",
        "else:\n",
        "    start_epoch = 0\n",
        "\n",
        "for i in range(start_epoch, 4):\n",
        "\n",
        "    if os.path.exists(\"Ego2Hand\"):\n",
        "        shutil.rmtree(\"Ego2Hand\")\n",
        "      \n",
        "    torch.manual_seed(42)\n",
        "    random.seed(42)\n",
        "    \n",
        "    extract_zip(subset_0_4, [8000*i, 8000*(i+1)])\n",
        "    extract_zip(subset_5_10, [8000*i, 8000*(i+1)])\n",
        "    extract_zip(subset_11_16, [8000*i, 8000*(i+1)])\n",
        "    extract_zip(subset_17_21, [8000*i, 8000*(i+1)])\n",
        "    \n",
        "    gtea_paths = GTEAPaths(\"GTEA\", seed=42)\n",
        "    ego_hand_paths = EgoHandPaths(\"EgoHand\", seed=42)\n",
        "    ego_2_hand_paths = Ego2HandPaths(\"Ego2Hand\", \"backgrounds\", seed=42)\n",
        "    paths = AugmentationPaths([*gtea_paths[:], *ego_hand_paths[:], *ego_2_hand_paths[:]], seed=42)\n",
        "    batches = split_on_batches(paths, 4)\n",
        "\n",
        "    fit(batches, Loader, preprocessor, model, optimizer, loss_fn, (i+1), \n",
        "        ckpt_path, 25, 25, history_path, meta_path, heatmap_input,\n",
        "        heatmap_output, 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OloJWOmwh2iM"
      },
      "source": [
        "create_checkpoint(ckpt_path, model, optimizer, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6B13O3FyHPc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}